{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   instance_id           artist_name            track_name  popularity  \\\n",
      "0      32894.0              Röyksopp  Röyksopp's Night Out        27.0   \n",
      "1      46652.0  Thievery Corporation      The Shining Path        31.0   \n",
      "2      30097.0        Dillon Francis             Hurricane        28.0   \n",
      "3      62177.0              Dubloadz                 Nitro        34.0   \n",
      "4      24907.0           What So Not      Divide & Conquer        32.0   \n",
      "\n",
      "   acousticness  danceability  duration_ms  energy  instrumentalness key  \\\n",
      "0       0.00468         0.652         -1.0   0.941           0.79200  A#   \n",
      "1       0.01270         0.622     218293.0   0.890           0.95000   D   \n",
      "2       0.00306         0.620     215613.0   0.755           0.01180  G#   \n",
      "3       0.02540         0.774     166875.0   0.700           0.00253  C#   \n",
      "4       0.00465         0.638     222369.0   0.587           0.90900  F#   \n",
      "\n",
      "   liveness  loudness   mode  speechiness               tempo obtained_date  \\\n",
      "0     0.115    -5.201  Minor       0.0748             100.889         4-Apr   \n",
      "1     0.124    -7.043  Minor       0.0300  115.00200000000001         4-Apr   \n",
      "2     0.534    -4.617  Major       0.0345             127.994         4-Apr   \n",
      "3     0.157    -4.498  Major       0.2390             128.014         4-Apr   \n",
      "4     0.157    -6.266  Major       0.0413             145.036         4-Apr   \n",
      "\n",
      "   valence music_genre  \n",
      "0    0.759  Electronic  \n",
      "1    0.531  Electronic  \n",
      "2    0.333  Electronic  \n",
      "3    0.270  Electronic  \n",
      "4    0.323  Electronic  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('music_genre.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By quickly taking a look at the tables above, we can immediatly observe some issues:\n",
    "\n",
    "1)  duration_ms has a negative value -1\n",
    "2)  key needs to be encoded not\n",
    "3)  mode needs to be encoded as a binary\n",
    "4)  tempo was read as a string, so needs to be converted to a numerical value\n",
    "5)  obtained_data is irrelevant and can be dropped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NaN values after cleaning:\n",
      "instance_id         0\n",
      "artist_name         0\n",
      "track_name          0\n",
      "popularity          0\n",
      "acousticness        0\n",
      "danceability        0\n",
      "duration_ms         0\n",
      "energy              0\n",
      "instrumentalness    0\n",
      "key                 0\n",
      "liveness            0\n",
      "loudness            0\n",
      "mode                0\n",
      "speechiness         0\n",
      "tempo               0\n",
      "valence             0\n",
      "music_genre         0\n",
      "dtype: int64\n",
      "\n",
      "Final check for NaN values in X_train before fitting the model:\n",
      "popularity          0\n",
      "acousticness        0\n",
      "danceability        0\n",
      "duration_ms         0\n",
      "energy              0\n",
      "instrumentalness    0\n",
      "key                 0\n",
      "liveness            0\n",
      "loudness            0\n",
      "mode                0\n",
      "speechiness         0\n",
      "tempo               0\n",
      "valence             0\n",
      "dtype: int64\n",
      "Accuracy: 0.5275\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Alternative       0.39      0.29      0.33      1008\n",
      "       Anime       0.61      0.60      0.61      1034\n",
      "       Blues       0.53      0.48      0.51      1021\n",
      "   Classical       0.77      0.80      0.78       955\n",
      "     Country       0.45      0.59      0.51       986\n",
      "  Electronic       0.58      0.58      0.58      1009\n",
      "     Hip-Hop       0.46      0.51      0.48       995\n",
      "        Jazz       0.49      0.42      0.45       985\n",
      "         Rap       0.47      0.37      0.42      1030\n",
      "        Rock       0.51      0.64      0.57       977\n",
      "\n",
      "    accuracy                           0.53     10000\n",
      "   macro avg       0.53      0.53      0.52     10000\n",
      "weighted avg       0.52      0.53      0.52     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with NaN values across the dataset\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# No need to handle 'duration_ms' and 'tempo' with apply and fillna now since NaNs are dropped\n",
    "\n",
    "# Drop 'obtained_date' column because irrelevant\n",
    "df.drop('obtained_date', axis=1, inplace=True)\n",
    "\n",
    "# Check for NaN values after all cleaning\n",
    "print(\"\\nNaN values after cleaning:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(['instance_id', 'artist_name', 'track_name', 'music_genre'], axis=1)\n",
    "Y = df['music_genre']\n",
    "\n",
    "# Encode categorical variables ('key', 'mode')\n",
    "categorical_features = ['key', 'mode']\n",
    "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Create a pipeline for numerical features\n",
    "numerical_pipeline = make_pipeline(\n",
    "    SimpleImputer(strategy='median'),  # This will fill NaNs with the median value of the feature\n",
    "    StandardScaler()\n",
    ")\n",
    "\n",
    "# Create a pipeline for categorical features\n",
    "categorical_pipeline = make_pipeline(\n",
    "    SimpleImputer(strategy='most_frequent'),  # This fills NaNs with the most frequent value of the feature\n",
    "    OneHotEncoder(handle_unknown='ignore')  # This handles any unknown categories encountered during transformation\n",
    ")\n",
    "\n",
    "# Create the column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_pipeline, numerical_features),\n",
    "        ('cat', categorical_pipeline, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Update the pipeline\n",
    "pipeline = make_pipeline(preprocessor, LogisticRegression(max_iter=1000))\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# After setting up the pipeline and before fitting the model, perform a final check for NaNs\n",
    "print(\"\\nFinal check for NaN values in X_train before fitting the model:\")\n",
    "print(X_train.isnull().sum())\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, Y_train)\n",
    "\n",
    "# Predict and evaluate the model\n",
    "predictions = pipeline.predict(X_test)\n",
    "print('Accuracy:', accuracy_score(Y_test, predictions))\n",
    "print(classification_report(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives an accuracy of 53% which isn't that great, let's move on to some strategies to improve the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5321\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Alternative       0.40      0.33      0.36      1008\n",
      "       Anime       0.76      0.74      0.75      1034\n",
      "       Blues       0.59      0.54      0.56      1021\n",
      "   Classical       0.81      0.85      0.83       955\n",
      "     Country       0.54      0.58      0.56       986\n",
      "  Electronic       0.64      0.61      0.63      1009\n",
      "     Hip-Hop       0.32      0.35      0.33       995\n",
      "        Jazz       0.52      0.48      0.50       985\n",
      "         Rap       0.30      0.28      0.29      1030\n",
      "        Rock       0.45      0.58      0.51       977\n",
      "\n",
      "    accuracy                           0.53     10000\n",
      "   macro avg       0.53      0.53      0.53     10000\n",
      "weighted avg       0.53      0.53      0.53     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Update the pipeline to use a Random Forest classifier\n",
    "pipeline = make_pipeline(preprocessor, RandomForestClassifier(random_state=42))\n",
    "\n",
    "# Fit the model\n",
    "pipeline.fit(X_train, Y_train)\n",
    "\n",
    "# Predict and evaluate the model\n",
    "predictions = pipeline.predict(X_test)\n",
    "print('Accuracy:', accuracy_score(Y_test, predictions))\n",
    "print(classification_report(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Best parameters: {'randomforestclassifier__max_depth': 10, 'randomforestclassifier__min_samples_leaf': 1, 'randomforestclassifier__min_samples_split': 5, 'randomforestclassifier__n_estimators': 200}\n",
      "Best cross-validation score: 0.5645249999999999\n",
      "Accuracy: 0.5563\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Alternative       0.52      0.26      0.35      1008\n",
      "       Anime       0.76      0.70      0.73      1034\n",
      "       Blues       0.60      0.49      0.54      1021\n",
      "   Classical       0.80      0.86      0.83       955\n",
      "     Country       0.52      0.57      0.54       986\n",
      "  Electronic       0.59      0.63      0.61      1009\n",
      "     Hip-Hop       0.42      0.57      0.48       995\n",
      "        Jazz       0.52      0.46      0.49       985\n",
      "         Rap       0.39      0.25      0.31      1030\n",
      "        Rock       0.47      0.81      0.60       977\n",
      "\n",
      "    accuracy                           0.56     10000\n",
      "   macro avg       0.56      0.56      0.55     10000\n",
      "weighted avg       0.56      0.56      0.55     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define a set of parameters to test\n",
    "param_grid = {\n",
    "    'randomforestclassifier__n_estimators': [100, 200],\n",
    "    'randomforestclassifier__max_depth': [None, 10],\n",
    "    'randomforestclassifier__min_samples_split': [2, 5],\n",
    "    'randomforestclassifier__min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, verbose=2, n_jobs=4)\n",
    "\n",
    "# Fit the model on the training data\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation score:\", grid_search.best_score_)\n",
    "\n",
    "# Predict and evaluate the model using the best found parameters\n",
    "best_predictions = grid_search.predict(X_test)\n",
    "print('Accuracy:', accuracy_score(Y_test, best_predictions))\n",
    "print(classification_report(Y_test, best_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using these parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5563\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Alternative       0.52      0.26      0.35      1008\n",
      "       Anime       0.76      0.70      0.73      1034\n",
      "       Blues       0.60      0.49      0.54      1021\n",
      "   Classical       0.80      0.86      0.83       955\n",
      "     Country       0.52      0.57      0.54       986\n",
      "  Electronic       0.59      0.63      0.61      1009\n",
      "     Hip-Hop       0.42      0.57      0.48       995\n",
      "        Jazz       0.52      0.46      0.49       985\n",
      "         Rap       0.39      0.25      0.31      1030\n",
      "        Rock       0.47      0.81      0.60       977\n",
      "\n",
      "    accuracy                           0.56     10000\n",
      "   macro avg       0.56      0.56      0.55     10000\n",
      "weighted avg       0.56      0.56      0.55     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Update the pipeline to use a Random Forest classifier with the best parameters found\n",
    "pipeline = make_pipeline(\n",
    "    preprocessor,\n",
    "    RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=10,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=1,\n",
    "        random_state=42\n",
    "    )\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "pipeline.fit(X_train, Y_train)\n",
    "\n",
    "# Predict and evaluate the model\n",
    "predictions = pipeline.predict(X_test)\n",
    "print('Accuracy:', accuracy_score(Y_test, predictions))\n",
    "print(classification_report(Y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5878\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Alternative       0.49      0.37      0.42      1008\n",
      "       Anime       0.82      0.74      0.78      1034\n",
      "       Blues       0.64      0.55      0.59      1021\n",
      "   Classical       0.84      0.84      0.84       955\n",
      "     Country       0.56      0.58      0.57       986\n",
      "  Electronic       0.68      0.64      0.66      1009\n",
      "     Hip-Hop       0.43      0.48      0.45       995\n",
      "        Jazz       0.53      0.53      0.53       985\n",
      "         Rap       0.44      0.41      0.42      1030\n",
      "        Rock       0.51      0.75      0.60       977\n",
      "\n",
      "    accuracy                           0.59     10000\n",
      "   macro avg       0.59      0.59      0.59     10000\n",
      "weighted avg       0.59      0.59      0.59     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Define the XGBoost classifier with some default parameters\n",
    "xgb_classifier = xgb.XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='mlogloss',  # For multiclass classification\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Encode string class labels to integers\n",
    "label_encoder = LabelEncoder()\n",
    "Y_train_encoded = label_encoder.fit_transform(Y_train)\n",
    "Y_test_encoded = label_encoder.transform(Y_test)\n",
    "\n",
    "# Update your pipeline\n",
    "pipeline = make_pipeline(preprocessor, xgb_classifier)\n",
    "\n",
    "# Fit the model on the encoded training data\n",
    "pipeline.fit(X_train, Y_train_encoded)\n",
    "\n",
    "# Predict and evaluate the model on the encoded test data\n",
    "predictions_encoded = pipeline.predict(X_test)\n",
    "predictions = label_encoder.inverse_transform(predictions_encoded)  # Decode the predictions back to original labels\n",
    "\n",
    "# Predict and evaluate the model\n",
    "predictions = pipeline.predict(X_test)\n",
    "print('Accuracy:', accuracy_score(Y_test_encoded, predictions_encoded))\n",
    "print(classification_report(Y_test_encoded, predictions_encoded, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define a new set of parameters to test\n",
    "param_grid = {\n",
    "    'xgbclassifier__n_estimators': [100, 300, 500],\n",
    "    'xgbclassifier__learning_rate': [0.05, 0.1, 0.2],\n",
    "    'xgbclassifier__max_depth': [3, 5, 7],\n",
    "    'xgbclassifier__subsample': [0.7, 0.8, 0.9],\n",
    "    'xgbclassifier__colsample_bytree': [0.7, 0.8, 0.9],\n",
    "    'xgbclassifier__reg_lambda': [1, 1.5, 2],\n",
    "    'xgbclassifier__reg_alpha': [0, 0.5, 1]\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# Fit the model on the encoded training data\n",
    "grid_search.fit(X_train, Y_train_encoded)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Best score\n",
    "print(\"Best cross-validation score:\", grid_search.best_score_)\n",
    "\n",
    "# Predict and evaluate the model using the best found parameters\n",
    "best_predictions_encoded = grid_search.predict(X_test)\n",
    "best_predictions = label_encoder.inverse_transform(best_predictions_encoded)\n",
    "\n",
    "print('Accuracy:', accuracy_score(Y_test_encoded, best_predictions_encoded))\n",
    "print(classification_report(Y_test_encoded, best_predictions_encoded, target_names=label_encoder.classes_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
