{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.activations import linear, relu, sigmoid\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "plt.style.use('./deeplearning.mplstyle')\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "tf.autograph.set_verbosity(0)\n",
    "\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing of the data\n",
    "#### First we drop the unused data, or NA values\n",
    "#### Then we convert the genres into numerical values so it can be used by the machine learning algorithm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50005 entries, 0 to 50004\n",
      "Data columns (total 18 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   instance_id       50000 non-null  float64\n",
      " 1   artist_name       50000 non-null  object \n",
      " 2   track_name        50000 non-null  object \n",
      " 3   popularity        50000 non-null  float64\n",
      " 4   acousticness      50000 non-null  float64\n",
      " 5   danceability      50000 non-null  float64\n",
      " 6   duration_ms       50000 non-null  float64\n",
      " 7   energy            50000 non-null  float64\n",
      " 8   instrumentalness  50000 non-null  float64\n",
      " 9   key               50000 non-null  object \n",
      " 10  liveness          50000 non-null  float64\n",
      " 11  loudness          50000 non-null  float64\n",
      " 12  mode              50000 non-null  object \n",
      " 13  speechiness       50000 non-null  float64\n",
      " 14  tempo             50000 non-null  object \n",
      " 15  obtained_date     50000 non-null  object \n",
      " 16  valence           50000 non-null  float64\n",
      " 17  music_genre       50000 non-null  object \n",
      "dtypes: float64(11), object(7)\n",
      "memory usage: 6.9+ MB\n"
     ]
    }
   ],
   "source": [
    "#load data, drop unnecessary columns, and drop all NA values\n",
    "df = pd.read_csv('music_genre.csv')\n",
    "df.info()\n",
    "features = ['instance_id','popularity','acousticness','danceability','duration_ms','energy','instrumentalness','key','liveness','loudness','mode','speechiness','tempo','valence']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The above features are proposed to do a first revision on the data, things like Artist name,  title and the obtained data are already left out, since they have no direct link to a specific genre. One could say that an artist would probably stick to a specific genre, but this knowledge is irrelevant to new artists, and would lead to overfitting. To check wether we should drop any other columns, we plot the distributions for all the remaining features for each specific genre using seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'mode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32md:\\conda\\envs\\tf\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32md:\\conda\\envs\\tf\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32md:\\conda\\envs\\tf\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'mode'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jens7\\Documents\\school\\master_ind\\Machine Learning\\project\\project_v1.ipynb Cell 5\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jens7/Documents/school/master_ind/Machine%20Learning/project/project_v1.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m encoder \u001b[39m=\u001b[39m LabelEncoder()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jens7/Documents/school/master_ind/Machine%20Learning/project/project_v1.ipynb#X30sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mmode\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m encoder\u001b[39m.\u001b[39mfit_transform(df[\u001b[39m'\u001b[39;49m\u001b[39mmode\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jens7/Documents/school/master_ind/Machine%20Learning/project/project_v1.ipynb#X30sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mkey\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m encoder\u001b[39m.\u001b[39mfit_transform(df[\u001b[39m'\u001b[39m\u001b[39mkey\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jens7/Documents/school/master_ind/Machine%20Learning/project/project_v1.ipynb#X30sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mtempo\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_numeric(df[\u001b[39m'\u001b[39m\u001b[39mtempo\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m), errors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcoerce\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32md:\\conda\\envs\\tf\\lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3808\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32md:\\conda\\envs\\tf\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'mode'"
     ]
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "\n",
    "df['mode'] = encoder.fit_transform(df['mode'])\n",
    "df['key'] = encoder.fit_transform(df['key'])\n",
    "df['tempo'] = pd.to_numeric(df['tempo'].str.replace('.', ''), errors='coerce')\n",
    "df['tempo'] = df['tempo'].fillna(0)\n",
    "\n",
    "for feature in features:\n",
    "    fig = sns.FacetGrid(df, hue=\"music_genre\", aspect=3, palette=\"Set2\") # aspect=3 permet d'allonger le graphique\n",
    "    fig.map(sns.kdeplot, feature, fill=True)\n",
    "    fig.add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To make a decision on what variables to drop based on the above graphs, we can analyze the distributions of each feature for each specific genre using seaborn. By observing the distributions, we can identify the features that have similar distributions across different genres, indicating that they may not contribute significantly to the classification task.\n",
    "\n",
    "#### Based on the graphs, it appears that the following features have similar distributions across genres and may not provide much discriminatory power:\n",
    "\n",
    "- instance_id\n",
    "- key\n",
    "- mode\n",
    "- tempo\n",
    "\n",
    "#### Therefore, we can consider dropping these variables from the dataset.\n",
    "\n",
    "#### There are also some parameters which differ a lot between genres, namely:\n",
    "\n",
    "- populatity\n",
    "- danceability\n",
    "- loudness\n",
    "- energy\n",
    "- acousticness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 50000 entries, 31004 to 48477\n",
      "Data columns (total 11 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   popularity        50000 non-null  float64\n",
      " 1   acousticness      50000 non-null  float64\n",
      " 2   danceability      50000 non-null  float64\n",
      " 3   duration_ms       50000 non-null  float64\n",
      " 4   energy            50000 non-null  float64\n",
      " 5   instrumentalness  50000 non-null  float64\n",
      " 6   liveness          50000 non-null  float64\n",
      " 7   loudness          50000 non-null  float64\n",
      " 8   speechiness       50000 non-null  float64\n",
      " 9   valence           50000 non-null  float64\n",
      " 10  music_genre       50000 non-null  int32  \n",
      "dtypes: float64(10), int32(1)\n",
      "memory usage: 4.4 MB\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(['instance_id', 'artist_name', 'track_name', 'key', 'mode','obtained_date','tempo'], axis=1) \n",
    "df = df.dropna()\n",
    "df = df.sample(frac=1)\n",
    "\n",
    "df['music_genre'] = encoder.fit_transform(df['music_genre'])\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "popularity          float64\n",
      "acousticness        float64\n",
      "danceability        float64\n",
      "duration_ms         float64\n",
      "energy              float64\n",
      "instrumentalness    float64\n",
      "liveness            float64\n",
      "loudness            float64\n",
      "speechiness         float64\n",
      "valence             float64\n",
      "music_genre           int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#since music_genre is of type \"object\" we can't apply the neural network to it, we need to encode it into, int this case, an integers\n",
    "encoder = LabelEncoder()\n",
    "df['music_genre'] = encoder.fit_transform(df['music_genre'])\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('music_genre', axis=1)\n",
    "Y = df['music_genre']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "size = X_train.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C3\n",
    "# GRADED CELL: model\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "\n",
    "tf.random.set_seed(1234)\n",
    "model = Sequential(\n",
    "    [\n",
    "        ### START CODE HERE ### \n",
    "        Dense(512, activation='relu'),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(10, activation='linear'),\n",
    "        \n",
    "        \n",
    "        ### END CODE HERE ### \n",
    "\n",
    "    ], name=\"Complex\"\n",
    ")\n",
    "model.compile(\n",
    "    ### START CODE HERE ### \n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer = tf.keras.optimizers.Adam(),\n",
    "    metrics=['accuracy']\n",
    "\n",
    "    ### END CODE HERE ### \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1250/1250 [==============================] - 4s 2ms/step - loss: 292.4460 - accuracy: 0.1155 - val_loss: 2.2487 - val_accuracy: 0.1195\n",
      "Epoch 2/100\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 2.3984 - accuracy: 0.1199 - val_loss: 2.2267 - val_accuracy: 0.1304\n",
      "Epoch 3/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.4658 - accuracy: 0.1268 - val_loss: 2.2204 - val_accuracy: 0.1337\n",
      "Epoch 4/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.3541 - accuracy: 0.1283 - val_loss: 2.2180 - val_accuracy: 0.1343\n",
      "Epoch 5/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.2452 - accuracy: 0.1310 - val_loss: 2.2157 - val_accuracy: 0.1338\n",
      "Epoch 6/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.2520 - accuracy: 0.1289 - val_loss: 2.2100 - val_accuracy: 0.1333\n",
      "Epoch 7/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.2138 - accuracy: 0.1327 - val_loss: 2.2175 - val_accuracy: 0.1306\n",
      "Epoch 8/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.2099 - accuracy: 0.1362 - val_loss: 2.2026 - val_accuracy: 0.1348\n",
      "Epoch 9/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.2988 - accuracy: 0.1379 - val_loss: 2.1958 - val_accuracy: 0.1422\n",
      "Epoch 10/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.7313 - accuracy: 0.1369 - val_loss: 2.2025 - val_accuracy: 0.1384\n",
      "Epoch 11/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.3076 - accuracy: 0.1344 - val_loss: 2.1998 - val_accuracy: 0.1410\n",
      "Epoch 12/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.2060 - accuracy: 0.1383 - val_loss: 2.2112 - val_accuracy: 0.1374\n",
      "Epoch 13/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 3.0171 - accuracy: 0.1378 - val_loss: 2.2059 - val_accuracy: 0.1356\n",
      "Epoch 14/100\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 2.6249 - accuracy: 0.1377 - val_loss: 2.2120 - val_accuracy: 0.1321\n",
      "Epoch 15/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.2039 - accuracy: 0.1400 - val_loss: 2.2004 - val_accuracy: 0.1378\n",
      "Epoch 16/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 3.5971 - accuracy: 0.1376 - val_loss: 2.2079 - val_accuracy: 0.1362\n",
      "Epoch 17/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.2017 - accuracy: 0.1379 - val_loss: 2.2010 - val_accuracy: 0.1388\n",
      "Epoch 18/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.2018 - accuracy: 0.1376 - val_loss: 2.2015 - val_accuracy: 0.1367\n",
      "Epoch 19/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.2002 - accuracy: 0.1380 - val_loss: 2.1986 - val_accuracy: 0.1384\n",
      "Epoch 20/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 3.0557 - accuracy: 0.1403 - val_loss: 2.2105 - val_accuracy: 0.1376\n",
      "Epoch 21/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.2054 - accuracy: 0.1420 - val_loss: 2.1915 - val_accuracy: 0.1408\n",
      "Epoch 22/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.1990 - accuracy: 0.1409 - val_loss: 2.1976 - val_accuracy: 0.1412\n",
      "Epoch 23/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.2179 - accuracy: 0.1417 - val_loss: 2.1940 - val_accuracy: 0.1424\n",
      "Epoch 24/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.2010 - accuracy: 0.1398 - val_loss: 2.1928 - val_accuracy: 0.1403\n",
      "Epoch 25/100\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 2.1961 - accuracy: 0.1376 - val_loss: 2.1928 - val_accuracy: 0.1415\n",
      "Epoch 26/100\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 2.1962 - accuracy: 0.1399 - val_loss: 2.1901 - val_accuracy: 0.1453\n",
      "Epoch 27/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.1947 - accuracy: 0.1411 - val_loss: 2.1929 - val_accuracy: 0.1425\n",
      "Epoch 28/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.2501 - accuracy: 0.1414 - val_loss: 2.1948 - val_accuracy: 0.1406\n",
      "Epoch 29/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.2092 - accuracy: 0.1422 - val_loss: 2.1948 - val_accuracy: 0.1392\n",
      "Epoch 30/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.1942 - accuracy: 0.1410 - val_loss: 2.1911 - val_accuracy: 0.1423\n",
      "Epoch 31/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.2721 - accuracy: 0.1410 - val_loss: 2.1914 - val_accuracy: 0.1455\n",
      "Epoch 32/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.2265 - accuracy: 0.1410 - val_loss: 2.1953 - val_accuracy: 0.1408\n",
      "Epoch 33/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.2045 - accuracy: 0.1395 - val_loss: 2.2008 - val_accuracy: 0.1428\n",
      "Epoch 34/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.1920 - accuracy: 0.1415 - val_loss: 2.1961 - val_accuracy: 0.1423\n",
      "Epoch 35/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.1950 - accuracy: 0.1397 - val_loss: 2.1983 - val_accuracy: 0.1399\n",
      "Epoch 36/100\n",
      "1250/1250 [==============================] - 4s 4ms/step - loss: 2.1904 - accuracy: 0.1426 - val_loss: 2.1937 - val_accuracy: 0.1417\n",
      "Epoch 37/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.5931 - accuracy: 0.1424 - val_loss: 2.2022 - val_accuracy: 0.1361\n",
      "Epoch 38/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.1900 - accuracy: 0.1410 - val_loss: 2.1966 - val_accuracy: 0.1408\n",
      "Epoch 39/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.1908 - accuracy: 0.1393 - val_loss: 2.1975 - val_accuracy: 0.1405\n",
      "Epoch 40/100\n",
      "1250/1250 [==============================] - 4s 4ms/step - loss: 2.1900 - accuracy: 0.1424 - val_loss: 2.1936 - val_accuracy: 0.1431\n",
      "Epoch 41/100\n",
      "1250/1250 [==============================] - 4s 4ms/step - loss: 2.1891 - accuracy: 0.1416 - val_loss: 2.1998 - val_accuracy: 0.1403\n",
      "Epoch 42/100\n",
      "1250/1250 [==============================] - 4s 4ms/step - loss: 2.1884 - accuracy: 0.1417 - val_loss: 2.1963 - val_accuracy: 0.1447\n",
      "Epoch 43/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.1884 - accuracy: 0.1438 - val_loss: 2.1916 - val_accuracy: 0.1427\n",
      "Epoch 44/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.1871 - accuracy: 0.1440 - val_loss: 2.2032 - val_accuracy: 0.1410\n",
      "Epoch 45/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.1891 - accuracy: 0.1446 - val_loss: 2.1999 - val_accuracy: 0.1388\n",
      "Epoch 46/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.1886 - accuracy: 0.1415 - val_loss: 2.1992 - val_accuracy: 0.1427\n",
      "Epoch 47/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.1872 - accuracy: 0.1427 - val_loss: 2.2023 - val_accuracy: 0.1422\n",
      "Epoch 48/100\n",
      "1250/1250 [==============================] - 4s 4ms/step - loss: 2.1868 - accuracy: 0.1452 - val_loss: 2.1919 - val_accuracy: 0.1418\n",
      "Epoch 49/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.1865 - accuracy: 0.1430 - val_loss: 2.1962 - val_accuracy: 0.1410\n",
      "Epoch 50/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.1865 - accuracy: 0.1457 - val_loss: 2.2052 - val_accuracy: 0.1411\n",
      "Epoch 51/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.1858 - accuracy: 0.1432 - val_loss: 2.1974 - val_accuracy: 0.1405\n",
      "Epoch 52/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.1859 - accuracy: 0.1422 - val_loss: 2.1954 - val_accuracy: 0.1434\n",
      "Epoch 53/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.1853 - accuracy: 0.1441 - val_loss: 2.1926 - val_accuracy: 0.1421\n",
      "Epoch 54/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.1844 - accuracy: 0.1444 - val_loss: 2.2011 - val_accuracy: 0.1411\n",
      "Epoch 55/100\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 2.1849 - accuracy: 0.1461 - val_loss: 2.1953 - val_accuracy: 0.1419\n",
      "Epoch 56/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.1833 - accuracy: 0.1455 - val_loss: 2.1989 - val_accuracy: 0.1424\n",
      "Epoch 57/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.1828 - accuracy: 0.1434 - val_loss: 2.2092 - val_accuracy: 0.1420\n",
      "Epoch 58/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.1831 - accuracy: 0.1446 - val_loss: 2.1970 - val_accuracy: 0.1411\n",
      "Epoch 59/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.1905 - accuracy: 0.1437 - val_loss: 2.1975 - val_accuracy: 0.1403\n",
      "Epoch 60/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.1826 - accuracy: 0.1435 - val_loss: 2.2035 - val_accuracy: 0.1417\n",
      "Epoch 61/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.1817 - accuracy: 0.1448 - val_loss: 2.2062 - val_accuracy: 0.1411\n",
      "Epoch 62/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.1815 - accuracy: 0.1446 - val_loss: 2.2017 - val_accuracy: 0.1415\n",
      "Epoch 63/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.1815 - accuracy: 0.1462 - val_loss: 2.1989 - val_accuracy: 0.1424\n",
      "Epoch 64/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.1801 - accuracy: 0.1464 - val_loss: 2.2094 - val_accuracy: 0.1381\n",
      "Epoch 65/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.4757 - accuracy: 0.1430 - val_loss: 2.1991 - val_accuracy: 0.1432\n",
      "Epoch 66/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.1805 - accuracy: 0.1461 - val_loss: 2.1983 - val_accuracy: 0.1425\n",
      "Epoch 67/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.1786 - accuracy: 0.1460 - val_loss: 2.2022 - val_accuracy: 0.1379\n",
      "Epoch 68/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.1783 - accuracy: 0.1440 - val_loss: 2.2204 - val_accuracy: 0.1403\n",
      "Epoch 69/100\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 2.1802 - accuracy: 0.1436 - val_loss: 2.2069 - val_accuracy: 0.1432\n",
      "Epoch 70/100\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 2.1783 - accuracy: 0.1450 - val_loss: 2.2043 - val_accuracy: 0.1426\n",
      "Epoch 71/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.1772 - accuracy: 0.1452 - val_loss: 2.2072 - val_accuracy: 0.1429\n",
      "Epoch 72/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.1772 - accuracy: 0.1459 - val_loss: 2.2023 - val_accuracy: 0.1429\n",
      "Epoch 73/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.1785 - accuracy: 0.1450 - val_loss: 2.2074 - val_accuracy: 0.1409\n",
      "Epoch 74/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.1765 - accuracy: 0.1479 - val_loss: 2.2033 - val_accuracy: 0.1408\n",
      "Epoch 75/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.1774 - accuracy: 0.1464 - val_loss: 2.2017 - val_accuracy: 0.1394\n",
      "Epoch 76/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.1782 - accuracy: 0.1470 - val_loss: 2.2046 - val_accuracy: 0.1397\n",
      "Epoch 77/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.1768 - accuracy: 0.1478 - val_loss: 2.2029 - val_accuracy: 0.1430\n",
      "Epoch 78/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.1749 - accuracy: 0.1436 - val_loss: 2.2019 - val_accuracy: 0.1426\n",
      "Epoch 79/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.1752 - accuracy: 0.1444 - val_loss: 2.2085 - val_accuracy: 0.1391\n",
      "Epoch 80/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.1753 - accuracy: 0.1468 - val_loss: 2.2101 - val_accuracy: 0.1419\n",
      "Epoch 81/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.1756 - accuracy: 0.1489 - val_loss: 2.2081 - val_accuracy: 0.1383\n",
      "Epoch 82/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 4.3697 - accuracy: 0.1436 - val_loss: 2.2062 - val_accuracy: 0.1435\n",
      "Epoch 83/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.1762 - accuracy: 0.1435 - val_loss: 2.2009 - val_accuracy: 0.1442\n",
      "Epoch 84/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.1756 - accuracy: 0.1456 - val_loss: 2.2047 - val_accuracy: 0.1434\n",
      "Epoch 85/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.1715 - accuracy: 0.1458 - val_loss: 2.2139 - val_accuracy: 0.1426\n",
      "Epoch 86/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.2577 - accuracy: 0.1471 - val_loss: 2.2052 - val_accuracy: 0.1412\n",
      "Epoch 87/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.1730 - accuracy: 0.1480 - val_loss: 2.2174 - val_accuracy: 0.1402\n",
      "Epoch 88/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.3235 - accuracy: 0.1494 - val_loss: 2.2067 - val_accuracy: 0.1444\n",
      "Epoch 89/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.1727 - accuracy: 0.1494 - val_loss: 2.2107 - val_accuracy: 0.1415\n",
      "Epoch 90/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.1719 - accuracy: 0.1508 - val_loss: 2.2075 - val_accuracy: 0.1410\n",
      "Epoch 91/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.2287 - accuracy: 0.1475 - val_loss: 2.2128 - val_accuracy: 0.1405\n",
      "Epoch 92/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.8478 - accuracy: 0.1461 - val_loss: 2.2070 - val_accuracy: 0.1428\n",
      "Epoch 93/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.1831 - accuracy: 0.1484 - val_loss: 2.2094 - val_accuracy: 0.1391\n",
      "Epoch 94/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.1703 - accuracy: 0.1493 - val_loss: 2.2137 - val_accuracy: 0.1425\n",
      "Epoch 95/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.1714 - accuracy: 0.1497 - val_loss: 2.2136 - val_accuracy: 0.1407\n",
      "Epoch 96/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.1696 - accuracy: 0.1466 - val_loss: 2.2104 - val_accuracy: 0.1399\n",
      "Epoch 97/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.1695 - accuracy: 0.1492 - val_loss: 2.2187 - val_accuracy: 0.1438\n",
      "Epoch 98/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.1686 - accuracy: 0.1510 - val_loss: 2.2196 - val_accuracy: 0.1392\n",
      "Epoch 99/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.1694 - accuracy: 0.1493 - val_loss: 2.2136 - val_accuracy: 0.1449\n",
      "Epoch 100/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.1705 - accuracy: 0.1468 - val_loss: 2.2200 - val_accuracy: 0.1413\n"
     ]
    }
   ],
   "source": [
    "train_2 = model.fit(X_train , Y_train , validation_data=(X_test,Y_test),epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 2.2200 - accuracy: 0.1413\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C2\n",
    "# GRADED CELL: eval_cat_err\n",
    "def eval_cat_err(y, yhat):\n",
    "    \"\"\" \n",
    "    Calculate the categorization error\n",
    "    Args:\n",
    "      y    : (ndarray  Shape (m,) or (m,1))  target value of each example\n",
    "      yhat : (ndarray  Shape (m,) or (m,1))  predicted value of each example\n",
    "    Returns:|\n",
    "      cerr: (scalar)             \n",
    "    \"\"\"\n",
    "    m = len(y)\n",
    "    incorrect = 0\n",
    "    #for i in range(m):\n",
    "    ### START CODE HERE ### \n",
    "    for i in range(m):\n",
    "        if (y[i] != yhat[i]):\n",
    "            incorrect+=1\n",
    "    cerr = incorrect/m        \n",
    "    ### END CODE HERE ### \n",
    "    \n",
    "    return(cerr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This result was the most optimal result obtained with the classical categorisation techniques seen in the lecture. But this is far from sufficiënt to classify the music genres, and more advanced techniques are needed.\n",
    "\n",
    "#### In the next part we alto try to run the same technique, but only with the very the data that differs a lot between all the different data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['speechiness', 'liveness', 'instrumentalness','acousticness'], axis=1) \n",
    "\n",
    "\n",
    "X = df.drop('music_genre', axis=1)\n",
    "Y = df['music_genre']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "size = X_train.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 735.1329 - accuracy: 0.1135 - val_loss: 174.6283 - val_accuracy: 0.1138\n",
      "Epoch 2/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 50.9369 - accuracy: 0.1181 - val_loss: 39.1868 - val_accuracy: 0.1244\n",
      "Epoch 3/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 16.2282 - accuracy: 0.1229 - val_loss: 6.3745 - val_accuracy: 0.1415\n",
      "Epoch 4/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 6.2684 - accuracy: 0.1286 - val_loss: 3.3257 - val_accuracy: 0.1598\n",
      "Epoch 5/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 4.2177 - accuracy: 0.1372 - val_loss: 3.1631 - val_accuracy: 0.1283\n",
      "Epoch 6/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.3924 - accuracy: 0.1413 - val_loss: 2.2468 - val_accuracy: 0.1275\n",
      "Epoch 7/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 4.9330 - accuracy: 0.1352 - val_loss: 2.3921 - val_accuracy: 0.1274\n",
      "Epoch 8/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 3.1572 - accuracy: 0.1355 - val_loss: 2.2394 - val_accuracy: 0.1294\n",
      "Epoch 9/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 2.3402 - accuracy: 0.1308 - val_loss: 2.2348 - val_accuracy: 0.1304\n",
      "Epoch 10/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 2.2215 - accuracy: 0.1301 - val_loss: 2.2179 - val_accuracy: 0.1297\n",
      "Epoch 11/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.2201 - accuracy: 0.1327 - val_loss: 2.2182 - val_accuracy: 0.1345\n",
      "Epoch 12/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.2197 - accuracy: 0.1319 - val_loss: 2.2123 - val_accuracy: 0.1320\n",
      "Epoch 13/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 2.2187 - accuracy: 0.1350 - val_loss: 2.2133 - val_accuracy: 0.1316\n",
      "Epoch 14/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 2.2172 - accuracy: 0.1315 - val_loss: 2.2166 - val_accuracy: 0.1297\n",
      "Epoch 15/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 2.6396 - accuracy: 0.1328 - val_loss: 2.2162 - val_accuracy: 0.1284\n",
      "Epoch 16/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 2.2160 - accuracy: 0.1324 - val_loss: 2.2129 - val_accuracy: 0.1329\n",
      "Epoch 17/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 2.2161 - accuracy: 0.1324 - val_loss: 2.2176 - val_accuracy: 0.1325\n",
      "Epoch 18/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 2.2162 - accuracy: 0.1344 - val_loss: 2.2181 - val_accuracy: 0.1296\n",
      "Epoch 19/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 2.2153 - accuracy: 0.1343 - val_loss: 2.2153 - val_accuracy: 0.1301\n",
      "Epoch 20/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 2.2148 - accuracy: 0.1354 - val_loss: 2.2208 - val_accuracy: 0.1278\n",
      "Epoch 21/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 3.9643 - accuracy: 0.1332 - val_loss: 2.2118 - val_accuracy: 0.1323\n",
      "Epoch 22/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 2.2783 - accuracy: 0.1338 - val_loss: 2.2111 - val_accuracy: 0.1309\n",
      "Epoch 23/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 2.2117 - accuracy: 0.1361 - val_loss: 2.2095 - val_accuracy: 0.1377\n",
      "Epoch 24/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 2.2685 - accuracy: 0.1351 - val_loss: 2.2085 - val_accuracy: 0.1334\n",
      "Epoch 25/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 2.2093 - accuracy: 0.1350 - val_loss: 2.2090 - val_accuracy: 0.1329\n",
      "Epoch 26/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 2.2095 - accuracy: 0.1347 - val_loss: 2.2152 - val_accuracy: 0.1311\n",
      "Epoch 27/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 2.2393 - accuracy: 0.1339 - val_loss: 2.2084 - val_accuracy: 0.1339\n",
      "Epoch 28/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 2.2090 - accuracy: 0.1353 - val_loss: 2.2084 - val_accuracy: 0.1328\n",
      "Epoch 29/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.2088 - accuracy: 0.1335 - val_loss: 2.2071 - val_accuracy: 0.1378\n",
      "Epoch 30/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.5954 - accuracy: 0.1349 - val_loss: 2.2086 - val_accuracy: 0.1342\n",
      "Epoch 31/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.9928 - accuracy: 0.1355 - val_loss: 2.2117 - val_accuracy: 0.1328\n",
      "Epoch 32/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.2503 - accuracy: 0.1362 - val_loss: 2.2085 - val_accuracy: 0.1338\n",
      "Epoch 33/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.2066 - accuracy: 0.1364 - val_loss: 2.2123 - val_accuracy: 0.1368\n",
      "Epoch 34/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.3073 - accuracy: 0.1377 - val_loss: 2.2052 - val_accuracy: 0.1359\n",
      "Epoch 35/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.2062 - accuracy: 0.1364 - val_loss: 2.2104 - val_accuracy: 0.1358\n",
      "Epoch 36/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.2068 - accuracy: 0.1356 - val_loss: 2.2131 - val_accuracy: 0.1305\n",
      "Epoch 37/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.2060 - accuracy: 0.1375 - val_loss: 2.2118 - val_accuracy: 0.1303\n",
      "Epoch 38/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.2060 - accuracy: 0.1365 - val_loss: 2.2088 - val_accuracy: 0.1371\n",
      "Epoch 39/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.2054 - accuracy: 0.1355 - val_loss: 2.2089 - val_accuracy: 0.1387\n",
      "Epoch 40/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.2044 - accuracy: 0.1384 - val_loss: 2.2160 - val_accuracy: 0.1307\n",
      "Epoch 41/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.2044 - accuracy: 0.1387 - val_loss: 2.2087 - val_accuracy: 0.1323\n",
      "Epoch 42/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.3575 - accuracy: 0.1382 - val_loss: 2.2075 - val_accuracy: 0.1319\n",
      "Epoch 43/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.2039 - accuracy: 0.1368 - val_loss: 2.2067 - val_accuracy: 0.1353\n",
      "Epoch 44/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.2032 - accuracy: 0.1367 - val_loss: 2.2089 - val_accuracy: 0.1345\n",
      "Epoch 45/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.2095 - accuracy: 0.1379 - val_loss: 2.2158 - val_accuracy: 0.1307\n",
      "Epoch 46/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.2026 - accuracy: 0.1399 - val_loss: 2.2108 - val_accuracy: 0.1336\n",
      "Epoch 47/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.2025 - accuracy: 0.1370 - val_loss: 2.2072 - val_accuracy: 0.1368\n",
      "Epoch 48/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.2027 - accuracy: 0.1377 - val_loss: 2.2163 - val_accuracy: 0.1322\n",
      "Epoch 49/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.7628 - accuracy: 0.1384 - val_loss: 2.2083 - val_accuracy: 0.1360\n",
      "Epoch 50/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.2020 - accuracy: 0.1385 - val_loss: 2.2152 - val_accuracy: 0.1381\n",
      "Epoch 51/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.2007 - accuracy: 0.1380 - val_loss: 2.2113 - val_accuracy: 0.1330\n",
      "Epoch 52/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 2.2019 - accuracy: 0.1369 - val_loss: 2.2179 - val_accuracy: 0.1315\n",
      "Epoch 53/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 4.8558 - accuracy: 0.1381 - val_loss: 2.2171 - val_accuracy: 0.1323\n",
      "Epoch 54/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.2015 - accuracy: 0.1382 - val_loss: 2.2114 - val_accuracy: 0.1321\n",
      "Epoch 55/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.5689 - accuracy: 0.1382 - val_loss: 2.2097 - val_accuracy: 0.1392\n",
      "Epoch 56/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.2170 - accuracy: 0.1384 - val_loss: 2.2098 - val_accuracy: 0.1329\n",
      "Epoch 57/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.2001 - accuracy: 0.1393 - val_loss: 2.2122 - val_accuracy: 0.1381\n",
      "Epoch 58/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.2008 - accuracy: 0.1376 - val_loss: 2.2102 - val_accuracy: 0.1328\n",
      "Epoch 59/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.2770 - accuracy: 0.1376 - val_loss: 2.2069 - val_accuracy: 0.1351\n",
      "Epoch 60/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.3604 - accuracy: 0.1391 - val_loss: 2.2122 - val_accuracy: 0.1335\n",
      "Epoch 61/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.2005 - accuracy: 0.1397 - val_loss: 2.2077 - val_accuracy: 0.1354\n",
      "Epoch 62/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 2.2005 - accuracy: 0.1372 - val_loss: 2.2117 - val_accuracy: 0.1380\n",
      "Epoch 63/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.1997 - accuracy: 0.1381 - val_loss: 2.2081 - val_accuracy: 0.1330\n",
      "Epoch 64/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.2005 - accuracy: 0.1394 - val_loss: 2.2068 - val_accuracy: 0.1342\n",
      "Epoch 65/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.1995 - accuracy: 0.1389 - val_loss: 2.2115 - val_accuracy: 0.1347\n",
      "Epoch 66/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 2.2002 - accuracy: 0.1390 - val_loss: 2.2114 - val_accuracy: 0.1326\n",
      "Epoch 67/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.3025 - accuracy: 0.1400 - val_loss: 2.2120 - val_accuracy: 0.1347\n",
      "Epoch 68/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 2.1991 - accuracy: 0.1397 - val_loss: 2.2119 - val_accuracy: 0.1366\n",
      "Epoch 69/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 2.1996 - accuracy: 0.1412 - val_loss: 2.2122 - val_accuracy: 0.1332\n",
      "Epoch 70/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 2.1989 - accuracy: 0.1397 - val_loss: 2.2125 - val_accuracy: 0.1329\n",
      "Epoch 71/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 2.2003 - accuracy: 0.1412 - val_loss: 2.2114 - val_accuracy: 0.1313\n",
      "Epoch 72/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 2.1985 - accuracy: 0.1411 - val_loss: 2.2131 - val_accuracy: 0.1403\n",
      "Epoch 73/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 2.2229 - accuracy: 0.1399 - val_loss: 2.2138 - val_accuracy: 0.1322\n",
      "Epoch 74/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.3284 - accuracy: 0.1380 - val_loss: 2.2154 - val_accuracy: 0.1326\n",
      "Epoch 75/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.1976 - accuracy: 0.1403 - val_loss: 2.2128 - val_accuracy: 0.1410\n",
      "Epoch 76/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.1978 - accuracy: 0.1387 - val_loss: 2.2135 - val_accuracy: 0.1344\n",
      "Epoch 77/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.1974 - accuracy: 0.1380 - val_loss: 2.2132 - val_accuracy: 0.1325\n",
      "Epoch 78/100\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 2.1974 - accuracy: 0.1388 - val_loss: 2.2145 - val_accuracy: 0.1332\n",
      "Epoch 79/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.1977 - accuracy: 0.1391 - val_loss: 2.2116 - val_accuracy: 0.1334\n",
      "Epoch 80/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.1970 - accuracy: 0.1409 - val_loss: 2.2117 - val_accuracy: 0.1331\n",
      "Epoch 81/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 5.7081 - accuracy: 0.1412 - val_loss: 2.2120 - val_accuracy: 0.1342\n",
      "Epoch 82/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.1969 - accuracy: 0.1390 - val_loss: 2.2151 - val_accuracy: 0.1384\n",
      "Epoch 83/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.1972 - accuracy: 0.1410 - val_loss: 2.2115 - val_accuracy: 0.1332\n",
      "Epoch 84/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.3011 - accuracy: 0.1394 - val_loss: 2.2142 - val_accuracy: 0.1339\n",
      "Epoch 85/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.1968 - accuracy: 0.1400 - val_loss: 2.2135 - val_accuracy: 0.1336\n",
      "Epoch 86/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.2004 - accuracy: 0.1408 - val_loss: 2.2102 - val_accuracy: 0.1396\n",
      "Epoch 87/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.1962 - accuracy: 0.1374 - val_loss: 2.2196 - val_accuracy: 0.1319\n",
      "Epoch 88/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.1972 - accuracy: 0.1388 - val_loss: 2.2164 - val_accuracy: 0.1313\n",
      "Epoch 89/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.1955 - accuracy: 0.1403 - val_loss: 2.2168 - val_accuracy: 0.1316\n",
      "Epoch 90/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.3773 - accuracy: 0.1404 - val_loss: 2.2224 - val_accuracy: 0.1369\n",
      "Epoch 91/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.1979 - accuracy: 0.1377 - val_loss: 2.2119 - val_accuracy: 0.1376\n",
      "Epoch 92/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.1960 - accuracy: 0.1417 - val_loss: 2.2208 - val_accuracy: 0.1343\n",
      "Epoch 93/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.1959 - accuracy: 0.1409 - val_loss: 2.2196 - val_accuracy: 0.1320\n",
      "Epoch 94/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.1960 - accuracy: 0.1417 - val_loss: 2.2145 - val_accuracy: 0.1343\n",
      "Epoch 95/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.1970 - accuracy: 0.1400 - val_loss: 2.2122 - val_accuracy: 0.1399\n",
      "Epoch 96/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.1953 - accuracy: 0.1415 - val_loss: 2.2122 - val_accuracy: 0.1324\n",
      "Epoch 97/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.1939 - accuracy: 0.1390 - val_loss: 2.2249 - val_accuracy: 0.1306\n",
      "Epoch 98/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.1972 - accuracy: 0.1400 - val_loss: 2.2155 - val_accuracy: 0.1333\n",
      "Epoch 99/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.1954 - accuracy: 0.1383 - val_loss: 2.2184 - val_accuracy: 0.1379\n",
      "Epoch 100/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 2.1955 - accuracy: 0.1369 - val_loss: 2.2135 - val_accuracy: 0.1326\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "\n",
    "tf.random.set_seed(1234)\n",
    "model = Sequential(\n",
    "    [\n",
    "        ### START CODE HERE ### \n",
    "        Dense(256, activation='relu'),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(10, activation='linear'),\n",
    "        \n",
    "        \n",
    "        ### END CODE HERE ### \n",
    "\n",
    "    ], name=\"Complex\"\n",
    ")\n",
    "model.compile(\n",
    "    ### START CODE HERE ### \n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer = tf.keras.optimizers.Adam(),\n",
    "    metrics=['accuracy']\n",
    "\n",
    "    ### END CODE HERE ### \n",
    "    # \n",
    ")\n",
    "train_2 = model.fit(X_train , Y_train , validation_data=(X_test,Y_test),epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 910us/step - loss: 2.2135 - accuracy: 0.1326\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This results is even worse result, so we stick to the first model\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
